{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practice Workspace.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMst6azXJuQ1On6RHs7+rSP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anitayadav3/EmotionRecognitionInConversation/blob/master/Practice_Workspace.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qM5GZTrvuE1u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "28db695d-1c6f-4db0-ce8d-4e4ec648e3f2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXlhBuXyuSOu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9e32f7f4-e53b-424a-aad0-20d3fc6092ae"
      },
      "source": [
        "%cd /content/gdrive/My Drive/DialogueRNN"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/DialogueRNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDxNAqRGvBa9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python train_IEMOCAP.py --dropout 0.4 --lr 0.0003 --batch-size 32 --class-weight --l2 0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BC6jZhh4_inc",
        "colab_type": "text"
      },
      "source": [
        "**Train_IEMOCAP file opened for practise**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExhBgwVpgMvy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(1234)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torch.optim as optim\n",
        "import argparse\n",
        "import time\n",
        "import pickle\n",
        "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score,\\\n",
        "                        classification_report, precision_recall_fscore_support\n",
        "from model import BiModel, Model, MaskedNLLLoss\n",
        "from dataloader import IEMOCAPDataset"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7PhgVOb_z2p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_train_valid_sampler(trainset, valid=0.1):\n",
        "    size = len(trainset)\n",
        "    idx = list(range(size))\n",
        "    split = int(valid*size)\n",
        "    return SubsetRandomSampler(idx[split:]), SubsetRandomSampler(idx[:split])\n",
        "\n",
        "def get_IEMOCAP_loaders(path, batch_size=32, valid=0.1, num_workers=0, pin_memory=False):\n",
        "    trainset = IEMOCAPDataset(path=path)\n",
        "    train_sampler, valid_sampler = get_train_valid_sampler(trainset, valid)\n",
        "    train_loader = DataLoader(trainset,\n",
        "                              batch_size=batch_size,\n",
        "                              sampler=train_sampler,\n",
        "                              collate_fn=trainset.collate_fn,\n",
        "                              num_workers=num_workers,\n",
        "                              pin_memory=pin_memory)\n",
        "    valid_loader = DataLoader(trainset,\n",
        "                              batch_size=batch_size,\n",
        "                              sampler=valid_sampler,\n",
        "                              collate_fn=trainset.collate_fn,\n",
        "                              num_workers=num_workers,\n",
        "                              pin_memory=pin_memory)\n",
        "\n",
        "    testset = IEMOCAPDataset(path=path, train=False)\n",
        "    test_loader = DataLoader(testset,\n",
        "                             batch_size=batch_size,\n",
        "                             collate_fn=testset.collate_fn,\n",
        "                             num_workers=num_workers,\n",
        "                             pin_memory=pin_memory)\n",
        "\n",
        "    return train_loader, valid_loader, test_loader\n",
        "\n",
        "def train_or_eval_model(model, loss_function, dataloader, epoch, optimizer=None, train=False):\n",
        "    losses = []\n",
        "    preds = []\n",
        "    labels = []\n",
        "    masks = []\n",
        "    alphas, alphas_f, alphas_b, vids = [], [], [], []\n",
        "    assert not train or optimizer!=None\n",
        "    if train:\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "    for data in dataloader:\n",
        "        if train:\n",
        "            optimizer.zero_grad()\n",
        "        # import ipdb;ipdb.set_trace()\n",
        "        textf, visuf, acouf, qmask, umask, label =\\\n",
        "                [d.cuda() for d in data[:-1]] if cuda else data[:-1]\n",
        "        #log_prob = model(torch.cat((textf,acouf,visuf),dim=-1), qmask,umask,att2=True) # seq_len, batch, n_classes\n",
        "        log_prob, alpha, alpha_f, alpha_b = model(textf, qmask,umask,att2=True) # seq_len, batch, n_classes\n",
        "        lp_ = log_prob.transpose(0,1).contiguous().view(-1,log_prob.size()[2]) # batch*seq_len, n_classes\n",
        "        labels_ = label.view(-1) # batch*seq_len\n",
        "        loss = loss_function(lp_, labels_, umask)\n",
        "\n",
        "        pred_ = torch.argmax(lp_,1) # batch*seq_len\n",
        "        preds.append(pred_.data.cpu().numpy())\n",
        "        labels.append(labels_.data.cpu().numpy())\n",
        "        masks.append(umask.view(-1).cpu().numpy())\n",
        "\n",
        "        losses.append(loss.item()*masks[-1].sum())\n",
        "        if train:\n",
        "            loss.backward()\n",
        "            if args.tensorboard:\n",
        "                for param in model.named_parameters():\n",
        "                    writer.add_histogram(param[0], param[1].grad, epoch)\n",
        "            optimizer.step()\n",
        "        else:\n",
        "            alphas += alpha\n",
        "            alphas_f += alpha_f\n",
        "            alphas_b += alpha_b\n",
        "            vids += data[-1]\n",
        "\n",
        "    if preds!=[]:\n",
        "        preds  = np.concatenate(preds)\n",
        "        labels = np.concatenate(labels)\n",
        "        masks  = np.concatenate(masks)\n",
        "    else:\n",
        "        return float('nan'), float('nan'), [], [], [], float('nan'),[]\n",
        "\n",
        "    avg_loss = round(np.sum(losses)/np.sum(masks),4)\n",
        "    avg_accuracy = round(accuracy_score(labels,preds,sample_weight=masks)*100,2)\n",
        "    avg_fscore = round(f1_score(labels,preds,sample_weight=masks,average='weighted')*100,2)\n",
        "    return avg_loss, avg_accuracy, labels, preds, masks,avg_fscore, [alphas, alphas_f, alphas_b, vids]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzEq64oq_6tG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cuda=torch.cuda.is_available()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaXnpjYzBCPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "n_classes  = 6\n",
        "n_epochs   = 60"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t58LXI32MAGq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "D_m = 100\n",
        "D_g = 500\n",
        "D_p = 500\n",
        "D_e = 300\n",
        "D_h = 300\n",
        "D_a = 100 # concat attention"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6WjEdo4MUpO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BiModel(D_m, D_g, D_p, D_e, D_h,\n",
        "                n_classes=n_classes,\n",
        "                listener_state=False,\n",
        "                context_attention='general',\n",
        "                dropout_rec=0.1,\n",
        "                dropout=0.4)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cBPiCy5POy2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_weights = torch.FloatTensor([\n",
        "                                    1/0.086747,\n",
        "                                    1/0.144406,\n",
        "                                    1/0.227883,\n",
        "                                    1/0.160585,\n",
        "                                    1/0.127711,\n",
        "                                    1/0.252668,\n",
        "                                      ])\n",
        "loss_function = MaskedNLLLoss()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qj8mxon1Qy6z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(),\n",
        "                           lr=0.0003,\n",
        "                           weight_decay=0.0)"
      ],
      "execution_count": 11,
      "outputs": []
    }
  ]
}
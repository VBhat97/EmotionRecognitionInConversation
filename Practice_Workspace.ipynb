{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practice Workspace.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN3lstFjKOH5vjrfMFcR2yO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anitayadav3/EmotionRecognitionInConversation/blob/master/Practice_Workspace.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qM5GZTrvuE1u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4e758fba-24ea-4bda-f99d-e87d5f561f2e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXlhBuXyuSOu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5487c95f-6212-43c7-d035-765c8921073e"
      },
      "source": [
        "%cd /content/gdrive/My Drive/DialogueRNN"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/DialogueRNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDxNAqRGvBa9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "29edcde7-4cdd-4800-ce02-eac29b1d522e"
      },
      "source": [
        "!python train_IEMOCAP.py --dropout 0.4 --lr 0.0003 --batch-size 32 --class-weight --l2 0.0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(active_listener=False, attention='general', batch_size=32, class_weight=True, dropout=0.4, epochs=60, l2=0.0, lr=0.0003, no_cuda=False, rec_dropout=0.1, tensorboard=False)\n",
            "Running on GPU\n",
            "epoch 1 train_loss 1.6546 train_acc 36.51 train_fscore35.66 valid_loss nan valid_acc nan val_fscorenan test_loss 1.4987 test_acc 55.21 test_fscore 50.33 time 7.58\n",
            "epoch 2 train_loss 1.2016 train_acc 59.66 train_fscore57.89 valid_loss nan valid_acc nan val_fscorenan test_loss 1.1435 test_acc 60.87 test_fscore 57.66 time 7.49\n",
            "epoch 3 train_loss 0.9009 train_acc 66.52 train_fscore65.38 valid_loss nan valid_acc nan val_fscorenan test_loss 0.9553 test_acc 65.0 test_fscore 63.64 time 7.42\n",
            "epoch 4 train_loss 0.7576 train_acc 71.0 train_fscore70.63 valid_loss nan valid_acc nan val_fscorenan test_loss 0.9234 test_acc 63.46 test_fscore 62.41 time 7.11\n",
            "epoch 5 train_loss 0.6671 train_acc 75.63 train_fscore75.46 valid_loss nan valid_acc nan val_fscorenan test_loss 0.9732 test_acc 62.66 test_fscore 62.31 time 7.26\n",
            "epoch 6 train_loss 0.6034 train_acc 78.43 train_fscore78.4 valid_loss nan valid_acc nan val_fscorenan test_loss 1.0012 test_acc 62.48 test_fscore 62.09 time 7.59\n",
            "epoch 7 train_loss 0.5397 train_acc 82.13 train_fscore82.12 valid_loss nan valid_acc nan val_fscorenan test_loss 1.0083 test_acc 62.42 test_fscore 62.1 time 7.62\n",
            "epoch 8 train_loss 0.476 train_acc 85.03 train_fscore85.01 valid_loss nan valid_acc nan val_fscorenan test_loss 1.037 test_acc 62.54 test_fscore 62.13 time 7.75\n",
            "epoch 9 train_loss 0.4307 train_acc 87.01 train_fscore86.97 valid_loss nan valid_acc nan val_fscorenan test_loss 1.0848 test_acc 61.43 test_fscore 61.46 time 7.53\n",
            "epoch 10 train_loss 0.3899 train_acc 88.74 train_fscore88.73 valid_loss nan valid_acc nan val_fscorenan test_loss 1.1385 test_acc 60.75 test_fscore 60.91 time 7.56\n",
            "epoch 11 train_loss 0.3511 train_acc 89.81 train_fscore89.82 valid_loss nan valid_acc nan val_fscorenan test_loss 1.1945 test_acc 59.46 test_fscore 59.67 time 7.41\n",
            "epoch 12 train_loss 0.325 train_acc 91.05 train_fscore91.06 valid_loss nan valid_acc nan val_fscorenan test_loss 1.2256 test_acc 59.03 test_fscore 59.15 time 7.47\n",
            "epoch 13 train_loss 0.3005 train_acc 91.76 train_fscore91.76 valid_loss nan valid_acc nan val_fscorenan test_loss 1.2249 test_acc 59.46 test_fscore 59.46 time 7.42\n",
            "epoch 14 train_loss 0.2875 train_acc 91.82 train_fscore91.82 valid_loss nan valid_acc nan val_fscorenan test_loss 1.2328 test_acc 60.38 test_fscore 60.21 time 7.56\n",
            "epoch 15 train_loss 0.286 train_acc 92.19 train_fscore92.18 valid_loss nan valid_acc nan val_fscorenan test_loss 1.2463 test_acc 60.69 test_fscore 60.44 time 7.6\n",
            "epoch 16 train_loss 0.2736 train_acc 92.17 train_fscore92.15 valid_loss nan valid_acc nan val_fscorenan test_loss 1.2635 test_acc 60.32 test_fscore 60.27 time 7.37\n",
            "epoch 17 train_loss 0.2539 train_acc 92.77 train_fscore92.75 valid_loss nan valid_acc nan val_fscorenan test_loss 1.2936 test_acc 59.64 test_fscore 59.73 time 7.44\n",
            "epoch 18 train_loss 0.2506 train_acc 92.72 train_fscore92.71 valid_loss nan valid_acc nan val_fscorenan test_loss 1.3206 test_acc 59.27 test_fscore 59.35 time 7.46\n",
            "epoch 19 train_loss 0.2586 train_acc 92.77 train_fscore92.77 valid_loss nan valid_acc nan val_fscorenan test_loss 1.2944 test_acc 59.46 test_fscore 59.44 time 7.72\n",
            "epoch 20 train_loss 0.2374 train_acc 93.17 train_fscore93.15 valid_loss nan valid_acc nan val_fscorenan test_loss 1.2991 test_acc 59.21 test_fscore 59.13 time 7.4\n",
            "epoch 21 train_loss 0.2248 train_acc 93.63 train_fscore93.62 valid_loss nan valid_acc nan val_fscorenan test_loss 1.335 test_acc 59.52 test_fscore 59.31 time 7.5\n",
            "epoch 22 train_loss 0.2395 train_acc 93.32 train_fscore93.31 valid_loss nan valid_acc nan val_fscorenan test_loss 1.3732 test_acc 58.96 test_fscore 58.72 time 7.39\n",
            "epoch 23 train_loss 0.2358 train_acc 93.72 train_fscore93.71 valid_loss nan valid_acc nan val_fscorenan test_loss 1.3964 test_acc 58.6 test_fscore 58.49 time 7.57\n",
            "epoch 24 train_loss 0.2244 train_acc 93.58 train_fscore93.57 valid_loss nan valid_acc nan val_fscorenan test_loss 1.4258 test_acc 58.04 test_fscore 57.84 time 7.15\n",
            "epoch 25 train_loss 0.2236 train_acc 93.79 train_fscore93.77 valid_loss nan valid_acc nan val_fscorenan test_loss 1.4023 test_acc 58.47 test_fscore 58.27 time 7.38\n",
            "epoch 26 train_loss 0.2117 train_acc 94.3 train_fscore94.29 valid_loss nan valid_acc nan val_fscorenan test_loss 1.3878 test_acc 58.78 test_fscore 58.56 time 7.52\n",
            "epoch 27 train_loss 0.2238 train_acc 93.73 train_fscore93.72 valid_loss nan valid_acc nan val_fscorenan test_loss 1.4054 test_acc 58.9 test_fscore 58.74 time 7.51\n",
            "epoch 28 train_loss 0.2081 train_acc 93.96 train_fscore93.94 valid_loss nan valid_acc nan val_fscorenan test_loss 1.4431 test_acc 57.67 test_fscore 57.56 time 7.8\n",
            "epoch 29 train_loss 0.1954 train_acc 94.7 train_fscore94.69 valid_loss nan valid_acc nan val_fscorenan test_loss 1.4521 test_acc 57.42 test_fscore 57.28 time 7.67\n",
            "epoch 30 train_loss 0.2013 train_acc 94.27 train_fscore94.26 valid_loss nan valid_acc nan val_fscorenan test_loss 1.4626 test_acc 57.12 test_fscore 56.91 time 7.71\n",
            "epoch 31 train_loss 0.2036 train_acc 94.06 train_fscore94.05 valid_loss nan valid_acc nan val_fscorenan test_loss 1.462 test_acc 57.12 test_fscore 56.96 time 7.8\n",
            "epoch 32 train_loss 0.2011 train_acc 94.34 train_fscore94.33 valid_loss nan valid_acc nan val_fscorenan test_loss 1.4674 test_acc 57.61 test_fscore 57.44 time 7.49\n",
            "epoch 33 train_loss 0.1946 train_acc 94.56 train_fscore94.55 valid_loss nan valid_acc nan val_fscorenan test_loss 1.4839 test_acc 57.98 test_fscore 57.84 time 7.54\n",
            "epoch 34 train_loss 0.1846 train_acc 94.91 train_fscore94.9 valid_loss nan valid_acc nan val_fscorenan test_loss 1.4955 test_acc 57.98 test_fscore 57.87 time 7.56\n",
            "epoch 35 train_loss 0.1953 train_acc 94.35 train_fscore94.35 valid_loss nan valid_acc nan val_fscorenan test_loss 1.503 test_acc 57.79 test_fscore 57.69 time 7.71\n",
            "epoch 36 train_loss 0.188 train_acc 94.41 train_fscore94.39 valid_loss nan valid_acc nan val_fscorenan test_loss 1.5098 test_acc 57.36 test_fscore 57.16 time 7.57\n",
            "epoch 37 train_loss 0.1829 train_acc 94.77 train_fscore94.76 valid_loss nan valid_acc nan val_fscorenan test_loss 1.5418 test_acc 57.12 test_fscore 56.85 time 7.7\n",
            "epoch 38 train_loss 0.1847 train_acc 94.54 train_fscore94.53 valid_loss nan valid_acc nan val_fscorenan test_loss 1.5448 test_acc 57.12 test_fscore 56.8 time 7.44\n",
            "epoch 39 train_loss 0.1728 train_acc 94.7 train_fscore94.68 valid_loss nan valid_acc nan val_fscorenan test_loss 1.544 test_acc 57.67 test_fscore 57.39 time 7.97\n",
            "epoch 40 train_loss 0.179 train_acc 94.73 train_fscore94.72 valid_loss nan valid_acc nan val_fscorenan test_loss 1.5509 test_acc 57.55 test_fscore 57.33 time 7.6\n",
            "epoch 41 train_loss 0.1747 train_acc 95.16 train_fscore95.16 valid_loss nan valid_acc nan val_fscorenan test_loss 1.5336 test_acc 57.49 test_fscore 57.36 time 7.7\n",
            "epoch 42 train_loss 0.1783 train_acc 94.73 train_fscore94.72 valid_loss nan valid_acc nan val_fscorenan test_loss 1.5417 test_acc 57.3 test_fscore 57.17 time 7.23\n",
            "epoch 43 train_loss 0.1743 train_acc 95.01 train_fscore95.0 valid_loss nan valid_acc nan val_fscorenan test_loss 1.58 test_acc 56.93 test_fscore 56.7 time 7.62\n",
            "epoch 44 train_loss 0.1774 train_acc 94.87 train_fscore94.86 valid_loss nan valid_acc nan val_fscorenan test_loss 1.6049 test_acc 56.56 test_fscore 56.27 time 7.49\n",
            "epoch 45 train_loss 0.1597 train_acc 95.63 train_fscore95.62 valid_loss nan valid_acc nan val_fscorenan test_loss 1.5711 test_acc 57.49 test_fscore 57.25 time 7.9\n",
            "epoch 46 train_loss 0.1635 train_acc 95.35 train_fscore95.34 valid_loss nan valid_acc nan val_fscorenan test_loss 1.525 test_acc 58.47 test_fscore 58.19 time 7.81\n",
            "epoch 47 train_loss 0.165 train_acc 95.28 train_fscore95.27 valid_loss nan valid_acc nan val_fscorenan test_loss 1.4924 test_acc 58.47 test_fscore 58.25 time 7.45\n",
            "epoch 48 train_loss 0.1612 train_acc 95.39 train_fscore95.38 valid_loss nan valid_acc nan val_fscorenan test_loss 1.4816 test_acc 58.53 test_fscore 58.37 time 7.51\n",
            "epoch 49 train_loss 0.1597 train_acc 95.2 train_fscore95.19 valid_loss nan valid_acc nan val_fscorenan test_loss 1.5098 test_acc 57.73 test_fscore 57.64 time 7.58\n",
            "epoch 50 train_loss 0.1611 train_acc 95.27 train_fscore95.26 valid_loss nan valid_acc nan val_fscorenan test_loss 1.5687 test_acc 57.67 test_fscore 57.49 time 8.0\n",
            "epoch 51 train_loss 0.1523 train_acc 95.58 train_fscore95.57 valid_loss nan valid_acc nan val_fscorenan test_loss 1.6186 test_acc 57.42 test_fscore 57.07 time 7.43\n",
            "epoch 52 train_loss 0.1555 train_acc 95.66 train_fscore95.65 valid_loss nan valid_acc nan val_fscorenan test_loss 1.6248 test_acc 57.42 test_fscore 57.04 time 7.56\n",
            "epoch 53 train_loss 0.1444 train_acc 95.78 train_fscore95.77 valid_loss nan valid_acc nan val_fscorenan test_loss 1.6079 test_acc 57.05 test_fscore 56.8 time 7.71\n",
            "epoch 54 train_loss 0.1486 train_acc 95.42 train_fscore95.41 valid_loss nan valid_acc nan val_fscorenan test_loss 1.6237 test_acc 56.93 test_fscore 56.7 time 7.61\n",
            "epoch 55 train_loss 0.1495 train_acc 95.59 train_fscore95.59 valid_loss nan valid_acc nan val_fscorenan test_loss 1.6516 test_acc 56.56 test_fscore 56.38 time 7.79\n",
            "epoch 56 train_loss 0.1442 train_acc 95.99 train_fscore95.98 valid_loss nan valid_acc nan val_fscorenan test_loss 1.6907 test_acc 56.5 test_fscore 56.28 time 8.06\n",
            "epoch 57 train_loss 0.1464 train_acc 95.94 train_fscore95.93 valid_loss nan valid_acc nan val_fscorenan test_loss 1.7098 test_acc 56.99 test_fscore 56.69 time 7.92\n",
            "epoch 58 train_loss 0.1436 train_acc 95.8 train_fscore95.79 valid_loss nan valid_acc nan val_fscorenan test_loss 1.6838 test_acc 56.19 test_fscore 55.95 time 7.45\n",
            "epoch 59 train_loss 0.1446 train_acc 95.65 train_fscore95.64 valid_loss nan valid_acc nan val_fscorenan test_loss 1.6731 test_acc 56.69 test_fscore 56.47 time 7.93\n",
            "epoch 60 train_loss 0.1445 train_acc 95.65 train_fscore95.64 valid_loss nan valid_acc nan val_fscorenan test_loss 1.6882 test_acc 56.38 test_fscore 56.14 time 7.97\n",
            "Test performance..\n",
            "Loss 0.9234 accuracy 63.46\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.4270    0.2639    0.3262     144.0\n",
            "           1     0.8060    0.8816    0.8421     245.0\n",
            "           2     0.5662    0.6458    0.6034     384.0\n",
            "           3     0.6818    0.5294    0.5960     170.0\n",
            "           4     0.6457    0.8227    0.7235     299.0\n",
            "           5     0.6095    0.5039    0.5517     381.0\n",
            "\n",
            "    accuracy                         0.6346    1623.0\n",
            "   macro avg     0.6227    0.6079    0.6072    1623.0\n",
            "weighted avg     0.6270    0.6346    0.6241    1623.0\n",
            "\n",
            "[[ 38.   1.  13.   0.  92.   0.]\n",
            " [  5. 216.   9.   3.   1.  11.]\n",
            " [ 12.  22. 248.  14.  37.  51.]\n",
            " [  0.   3.  17.  90.   0.  60.]\n",
            " [ 34.   1.  17.   0. 246.   1.]\n",
            " [  0.  25. 134.  25.   5. 192.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BC6jZhh4_inc",
        "colab_type": "text"
      },
      "source": [
        "**Train_IEMOCAP file opened for practise**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExhBgwVpgMvy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(1234)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torch.optim as optim\n",
        "import argparse\n",
        "import time\n",
        "import pickle\n",
        "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score,\\\n",
        "                        classification_report, precision_recall_fscore_support\n",
        "from model import BiModel, Model, MaskedNLLLoss\n",
        "from dataloader import IEMOCAPDataset"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7PhgVOb_z2p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_train_valid_sampler(trainset, valid=0.1):\n",
        "    size = len(trainset)\n",
        "    idx = list(range(size))\n",
        "    split = int(valid*size)\n",
        "    return SubsetRandomSampler(idx[split:]), SubsetRandomSampler(idx[:split])\n",
        "\n",
        "def get_IEMOCAP_loaders(path, batch_size=32, valid=0.1, num_workers=0, pin_memory=False):\n",
        "    trainset = IEMOCAPDataset(path=path)\n",
        "    train_sampler, valid_sampler = get_train_valid_sampler(trainset, valid)\n",
        "    train_loader = DataLoader(trainset,\n",
        "                              batch_size=batch_size,\n",
        "                              sampler=train_sampler,\n",
        "                              collate_fn=trainset.collate_fn,\n",
        "                              num_workers=num_workers,\n",
        "                              pin_memory=pin_memory)\n",
        "    valid_loader = DataLoader(trainset,\n",
        "                              batch_size=batch_size,\n",
        "                              sampler=valid_sampler,\n",
        "                              collate_fn=trainset.collate_fn,\n",
        "                              num_workers=num_workers,\n",
        "                              pin_memory=pin_memory)\n",
        "\n",
        "    testset = IEMOCAPDataset(path=path, train=False)\n",
        "    test_loader = DataLoader(testset,\n",
        "                             batch_size=batch_size,\n",
        "                             collate_fn=testset.collate_fn,\n",
        "                             num_workers=num_workers,\n",
        "                             pin_memory=pin_memory)\n",
        "\n",
        "    return train_loader, valid_loader, test_loader\n",
        "\n",
        "def train_or_eval_model(model, loss_function, dataloader, epoch, optimizer=None, train=False):\n",
        "    losses = []\n",
        "    preds = []\n",
        "    labels = []\n",
        "    masks = []\n",
        "    alphas, alphas_f, alphas_b, vids = [], [], [], []\n",
        "    assert not train or optimizer!=None\n",
        "    if train:\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "    for data in dataloader:\n",
        "        if train:\n",
        "            optimizer.zero_grad()\n",
        "        # import ipdb;ipdb.set_trace()\n",
        "        textf, visuf, acouf, qmask, umask, label =\\\n",
        "                [d.cuda() for d in data[:-1]] if cuda else data[:-1]\n",
        "        #log_prob = model(torch.cat((textf,acouf,visuf),dim=-1), qmask,umask,att2=True) # seq_len, batch, n_classes\n",
        "        log_prob, alpha, alpha_f, alpha_b = model(textf, qmask,umask,att2=True) # seq_len, batch, n_classes\n",
        "        lp_ = log_prob.transpose(0,1).contiguous().view(-1,log_prob.size()[2]) # batch*seq_len, n_classes\n",
        "        labels_ = label.view(-1) # batch*seq_len\n",
        "        loss = loss_function(lp_, labels_, umask)\n",
        "\n",
        "        pred_ = torch.argmax(lp_,1) # batch*seq_len\n",
        "        preds.append(pred_.data.cpu().numpy())\n",
        "        labels.append(labels_.data.cpu().numpy())\n",
        "        masks.append(umask.view(-1).cpu().numpy())\n",
        "\n",
        "        losses.append(loss.item()*masks[-1].sum())\n",
        "        if train:\n",
        "            loss.backward()\n",
        "            if args.tensorboard:\n",
        "                for param in model.named_parameters():\n",
        "                    writer.add_histogram(param[0], param[1].grad, epoch)\n",
        "            optimizer.step()\n",
        "        else:\n",
        "            alphas += alpha\n",
        "            alphas_f += alpha_f\n",
        "            alphas_b += alpha_b\n",
        "            vids += data[-1]\n",
        "\n",
        "    if preds!=[]:\n",
        "        preds  = np.concatenate(preds)\n",
        "        labels = np.concatenate(labels)\n",
        "        masks  = np.concatenate(masks)\n",
        "    else:\n",
        "        return float('nan'), float('nan'), [], [], [], float('nan'),[]\n",
        "\n",
        "    avg_loss = round(np.sum(losses)/np.sum(masks),4)\n",
        "    avg_accuracy = round(accuracy_score(labels,preds,sample_weight=masks)*100,2)\n",
        "    avg_fscore = round(f1_score(labels,preds,sample_weight=masks,average='weighted')*100,2)\n",
        "    return avg_loss, avg_accuracy, labels, preds, masks,avg_fscore, [alphas, alphas_f, alphas_b, vids]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzEq64oq_6tG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
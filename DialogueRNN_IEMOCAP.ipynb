{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DialogueRNN_IEMOCAP.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anitayadav3/EmotionRecognitionInConversation/blob/master/DialogueRNN_IEMOCAP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMPy2Xc47HW-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorboardX\n",
        "!pip install pytorch_pretrained_bert"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywo5IE-DqQKx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9e7deddb-2df2-4214-c859-4d9ed217e03e"
      },
      "source": [
        "print('test')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffL9Ngmv9LgA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "75cec906-85d8-493f-d2fe-343bb3cfbf01"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E11SeqCHJ31S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7fec39e0-faf5-4e83-cc7a-11f3dbfada6b"
      },
      "source": [
        "%cd /content/gdrive/My Drive/DialogueGCN"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/DialogueGCN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul56QTT6KWIZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 843
        },
        "outputId": "e6097bcd-d782-4b9a-b94d-1d278acacb06"
      },
      "source": [
        "!pip install torch_geometric"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch_geometric\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/67/6c0bce6b6e6bc806e25d996e46a686e5a11254d89257983265a988bb02ee/torch_geometric-1.6.1.tar.gz (178kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torch_geometric) (1.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch_geometric) (1.18.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torch_geometric) (4.41.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch_geometric) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from torch_geometric) (2.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from torch_geometric) (0.22.2.post1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.6/dist-packages (from torch_geometric) (0.48.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torch_geometric) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from torch_geometric) (1.0.5)\n",
            "Collecting rdflib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/6b/6454aa1db753c0f8bc265a5bd5c10b5721a4bb24160fb4faf758cf6be8a1/rdflib-5.0.0-py3-none-any.whl (231kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 15.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from torch_geometric) (2.10.0)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.6/dist-packages (from torch_geometric) (0.4)\n",
            "Collecting ase\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/78/edadb45c7f26f8fbb99da81feadb561c26bb0393b6c5d1ac200ecdc12d61/ase-3.20.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 15.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from torch_geometric) (2.11.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torch_geometric) (0.16.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->torch_geometric) (4.4.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->torch_geometric) (0.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba->torch_geometric) (50.3.0)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba->torch_geometric) (0.31.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torch_geometric) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torch_geometric) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torch_geometric) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torch_geometric) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->torch_geometric) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->torch_geometric) (2018.9)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from rdflib->torch_geometric) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from rdflib->torch_geometric) (1.15.0)\n",
            "Collecting isodate\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from ase->torch_geometric) (3.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->torch_geometric) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->ase->torch_geometric) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->ase->torch_geometric) (1.2.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-1.6.1-cp36-none-any.whl size=308552 sha256=3c7e2fcb3f65c716e0d18149594a58aedccfca895f5641b2478b78048e364c17\n",
            "  Stored in directory: /root/.cache/pip/wheels/e6/25/ea/3d71d2088dccc63214fa59259dcc598ded4150a5f8b41d84ff\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: isodate, rdflib, ase, torch-geometric\n",
            "Successfully installed ase-3.20.1 isodate-0.6.0 rdflib-5.0.0 torch-geometric-1.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGkdRLGlKpxy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "a77d6597-98c2-4be0-ed2b-5aab16b9897e"
      },
      "source": [
        "!pip install torch_sparse"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch_sparse\n",
            "  Using cached https://files.pythonhosted.org/packages/ce/c0/f5ccc280629765cf1e97b601426cad6170d00603cf9836ba52f85d44ac27/torch_sparse-0.6.7.tar.gz\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch_sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->torch_sparse) (1.18.5)\n",
            "Building wheels for collected packages: torch-sparse\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.6.7-cp36-cp36m-linux_x86_64.whl size=22081698 sha256=23c8dfb223c565cb4f02ac6fb3711df2e350a8c456ff41678cf2bc0bd7e32b5b\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/54/57/495938ad744a865b8933e76fa71853495f2ac476475d49a9a2\n",
            "Successfully built torch-sparse\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPmAS7KfPymU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "b5fe77b4-e248-4844-8eed-b50d8fe7a1ad"
      },
      "source": [
        "!pip install torch_scatter"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch_scatter\n",
            "  Downloading https://files.pythonhosted.org/packages/01/45/cd93ed3227248773ba8bc4b3beaa04e8bddb127a793a41bad875369951b3/torch_scatter-2.0.5.tar.gz\n",
            "Building wheels for collected packages: torch-scatter\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.0.5-cp36-cp36m-linux_x86_64.whl size=11359537 sha256=aac5620f7a6d436aec69f46e4cf8382791097b1c796fe49af9a3ad9408e371a8\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/59/d3/9866e4fd8e1fe9260740acfe22322c428bc0dc064d3ebc456c\n",
            "Successfully built torch-scatter\n",
            "Installing collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkknuZjTJeNb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "outputId": "e37aa1cd-a49a-4378-8cb8-75a6fa4ae4dc"
      },
      "source": [
        "!python train_IEMOCAP.py --base-model 'LSTM' --graph-model --nodal-attention --dropout 0.4 --lr 0.0003 --batch-size 32 --class-weight --l2 0.0 --no-cuda"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(active_listener=False, attention='general', base_model='LSTM', batch_size=32, class_weight=True, dropout=0.4, epochs=60, graph_model=True, l2=0.0, lr=0.0003, no_cuda=True, nodal_attention=True, rec_dropout=0.1, tensorboard=False, windowf=10, windowp=10)\n",
            "Running on CPU\n",
            "Graph NN with LSTM as base model.\n",
            "train_IEMOCAP.py:140: UserWarning: This overload of nonzero is deprecated:\n",
            "\tnonzero()\n",
            "Consider using one of the following signatures instead:\n",
            "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
            "  lengths = [(umask[j] == 1).nonzero().tolist()[-1][0] + 1 for j in range(len(umask))]\n",
            "Traceback (most recent call last):\n",
            "  File \"train_IEMOCAP.py\", line 333, in <module>\n",
            "    train_loss, train_acc, _, _, train_fscore, _, _, _, _, _ = train_or_eval_graph_model(model, loss_function, train_loader, e, cuda, optimizer, True)\n",
            "  File \"train_IEMOCAP.py\", line 142, in train_or_eval_graph_model\n",
            "    log_prob, e_i, e_n, e_t, e_l = model(textf, qmask, umask, lengths)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/gdrive/My Drive/DialogueGCN/model.py\", line 906, in forward\n",
            "    log_prob = self.graph_net(features, edge_index, edge_norm, edge_type, seq_lengths, umask, self.nodal_attention, self.avec)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/gdrive/My Drive/DialogueGCN/model.py\", line 806, in forward\n",
            "    out = self.conv1(x, edge_index, edge_type, edge_norm)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "TypeError: forward() takes from 3 to 4 positional arguments but 5 were given\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbP6juklTFuC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e3e584d6-0682-4ae5-b5d0-4b6305aa72b2"
      },
      "source": [
        "%cd /content/gdrive/My Drive/DialogueGCN-mianzhang\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/DialogueGCN-mianzhang\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlI5VDL0Tg7Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e801ccbe-14e3-426a-e4b4-220114b49bad"
      },
      "source": [
        "%cd scripts/ "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/DialogueGCN-mianzhang/scripts\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYbRtLwMs5zN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0f7ee99c-5329-4aa2-e23e-5b68bad3017e"
      },
      "source": [
        "%cd /content/gdrive/My Drive/DialogueRNN"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/DialogueRNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8lbv2Iss1M_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "355fe2ff-3217-4e1d-e4c5-1ad14eed5a9f"
      },
      "source": [
        "!python train_IEMOCAP.py --dropout 0.4 --lr 0.0003 --batch-size 32 --class-weight --l2 0.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(active_listener=False, attention='general', batch_size=32, class_weight=True, dropout=0.4, epochs=60, l2=0.0, lr=0.0003, no_cuda=False, rec_dropout=0.1, tensorboard=False)\n",
            "Running on GPU\n",
            "epoch 1 train_loss 1.6609 train_acc 33.67 train_fscore31.98 valid_loss nan valid_acc nan val_fscorenan test_loss 1.4813 test_acc 53.54 test_fscore 45.08 time 8.0\n",
            "epoch 2 train_loss 1.2446 train_acc 53.82 train_fscore49.78 valid_loss nan valid_acc nan val_fscorenan test_loss 1.1365 test_acc 60.01 test_fscore 54.85 time 8.02\n",
            "epoch 3 train_loss 0.972 train_acc 61.36 train_fscore59.06 valid_loss nan valid_acc nan val_fscorenan test_loss 0.9976 test_acc 61.8 test_fscore 61.06 time 7.51\n",
            "epoch 4 train_loss 0.8262 train_acc 65.96 train_fscore65.03 valid_loss nan valid_acc nan val_fscorenan test_loss 0.9228 test_acc 63.96 test_fscore 63.05 time 7.7\n",
            "epoch 5 train_loss 0.7256 train_acc 71.45 train_fscore71.18 valid_loss nan valid_acc nan val_fscorenan test_loss 0.9549 test_acc 62.66 test_fscore 62.35 time 8.14\n",
            "epoch 6 train_loss 0.6586 train_acc 75.65 train_fscore75.54 valid_loss nan valid_acc nan val_fscorenan test_loss 0.9836 test_acc 61.06 test_fscore 61.0 time 8.19\n",
            "epoch 7 train_loss 0.5993 train_acc 78.26 train_fscore78.01 valid_loss nan valid_acc nan val_fscorenan test_loss 0.9924 test_acc 62.48 test_fscore 62.24 time 7.75\n",
            "epoch 8 train_loss 0.5298 train_acc 81.81 train_fscore81.71 valid_loss nan valid_acc nan val_fscorenan test_loss 1.014 test_acc 61.68 test_fscore 61.65 time 7.84\n",
            "epoch 9 train_loss 0.4742 train_acc 84.7 train_fscore84.67 valid_loss nan valid_acc nan val_fscorenan test_loss 1.0506 test_acc 60.01 test_fscore 60.0 time 8.36\n",
            "epoch 10 train_loss 0.4127 train_acc 87.09 train_fscore87.06 valid_loss nan valid_acc nan val_fscorenan test_loss 1.1055 test_acc 59.4 test_fscore 59.39 time 8.07\n",
            "epoch 11 train_loss 0.3888 train_acc 88.52 train_fscore88.52 valid_loss nan valid_acc nan val_fscorenan test_loss 1.1477 test_acc 59.64 test_fscore 59.61 time 8.65\n",
            "epoch 12 train_loss 0.3575 train_acc 89.93 train_fscore89.94 valid_loss nan valid_acc nan val_fscorenan test_loss 1.1793 test_acc 59.52 test_fscore 59.47 time 8.22\n",
            "epoch 13 train_loss 0.3302 train_acc 90.36 train_fscore90.37 valid_loss nan valid_acc nan val_fscorenan test_loss 1.201 test_acc 60.07 test_fscore 59.97 time 8.49\n",
            "epoch 14 train_loss 0.3041 train_acc 91.2 train_fscore91.21 valid_loss nan valid_acc nan val_fscorenan test_loss 1.2372 test_acc 59.64 test_fscore 59.4 time 8.53\n",
            "epoch 15 train_loss 0.2863 train_acc 91.86 train_fscore91.84 valid_loss nan valid_acc nan val_fscorenan test_loss 1.2775 test_acc 59.7 test_fscore 59.28 time 7.98\n",
            "epoch 16 train_loss 0.2666 train_acc 92.46 train_fscore92.44 valid_loss nan valid_acc nan val_fscorenan test_loss 1.2884 test_acc 59.21 test_fscore 58.99 time 8.18\n",
            "epoch 17 train_loss 0.2627 train_acc 92.51 train_fscore92.51 valid_loss nan valid_acc nan val_fscorenan test_loss 1.2942 test_acc 59.27 test_fscore 59.22 time 7.67\n",
            "epoch 18 train_loss 0.2517 train_acc 92.79 train_fscore92.78 valid_loss nan valid_acc nan val_fscorenan test_loss 1.3068 test_acc 58.72 test_fscore 58.73 time 8.61\n",
            "epoch 19 train_loss 0.2495 train_acc 92.82 train_fscore92.81 valid_loss nan valid_acc nan val_fscorenan test_loss 1.3419 test_acc 58.84 test_fscore 58.7 time 8.11\n",
            "epoch 20 train_loss 0.2505 train_acc 92.79 train_fscore92.77 valid_loss nan valid_acc nan val_fscorenan test_loss 1.3676 test_acc 58.66 test_fscore 58.39 time 7.91\n",
            "epoch 21 train_loss 0.2366 train_acc 93.15 train_fscore93.13 valid_loss nan valid_acc nan val_fscorenan test_loss 1.3886 test_acc 57.36 test_fscore 57.13 time 8.26\n",
            "epoch 22 train_loss 0.2221 train_acc 93.7 train_fscore93.69 valid_loss nan valid_acc nan val_fscorenan test_loss 1.4148 test_acc 56.93 test_fscore 56.66 time 8.29\n",
            "epoch 23 train_loss 0.2291 train_acc 93.24 train_fscore93.22 valid_loss nan valid_acc nan val_fscorenan test_loss 1.4578 test_acc 56.69 test_fscore 56.37 time 8.01\n",
            "epoch 24 train_loss 0.2143 train_acc 93.82 train_fscore93.81 valid_loss nan valid_acc nan val_fscorenan test_loss 1.5088 test_acc 56.56 test_fscore 56.32 time 8.1\n",
            "epoch 25 train_loss 0.2228 train_acc 93.63 train_fscore93.62 valid_loss nan valid_acc nan val_fscorenan test_loss 1.5196 test_acc 55.7 test_fscore 55.56 time 8.45\n",
            "epoch 26 train_loss 0.2116 train_acc 93.89 train_fscore93.89 valid_loss nan valid_acc nan val_fscorenan test_loss 1.4834 test_acc 56.62 test_fscore 56.44 time 8.1\n",
            "epoch 27 train_loss 0.1983 train_acc 93.98 train_fscore93.96 valid_loss nan valid_acc nan val_fscorenan test_loss 1.4643 test_acc 57.36 test_fscore 57.22 time 8.42\n",
            "epoch 28 train_loss 0.2097 train_acc 94.01 train_fscore93.99 valid_loss nan valid_acc nan val_fscorenan test_loss 1.4878 test_acc 57.86 test_fscore 57.7 time 7.52\n",
            "epoch 29 train_loss 0.2011 train_acc 94.39 train_fscore94.38 valid_loss nan valid_acc nan val_fscorenan test_loss 1.482 test_acc 57.61 test_fscore 57.47 time 7.95\n",
            "epoch 30 train_loss 0.2032 train_acc 94.08 train_fscore94.07 valid_loss nan valid_acc nan val_fscorenan test_loss 1.4702 test_acc 57.36 test_fscore 57.24 time 7.73\n",
            "epoch 31 train_loss 0.2033 train_acc 94.35 train_fscore94.34 valid_loss nan valid_acc nan val_fscorenan test_loss 1.4641 test_acc 57.42 test_fscore 57.29 time 7.84\n",
            "epoch 32 train_loss 0.1953 train_acc 94.48 train_fscore94.46 valid_loss nan valid_acc nan val_fscorenan test_loss 1.451 test_acc 57.36 test_fscore 57.11 time 7.83\n",
            "epoch 33 train_loss 0.2031 train_acc 94.03 train_fscore94.01 valid_loss nan valid_acc nan val_fscorenan test_loss 1.451 test_acc 57.36 test_fscore 57.2 time 7.91\n",
            "epoch 34 train_loss 0.1945 train_acc 94.08 train_fscore94.06 valid_loss nan valid_acc nan val_fscorenan test_loss 1.4851 test_acc 57.3 test_fscore 57.19 time 7.81\n",
            "epoch 35 train_loss 0.189 train_acc 94.48 train_fscore94.47 valid_loss nan valid_acc nan val_fscorenan test_loss 1.4954 test_acc 57.49 test_fscore 57.34 time 7.96\n",
            "epoch 36 train_loss 0.1875 train_acc 94.51 train_fscore94.5 valid_loss nan valid_acc nan val_fscorenan test_loss 1.4947 test_acc 57.18 test_fscore 56.98 time 8.14\n",
            "epoch 37 train_loss 0.1816 train_acc 94.6 train_fscore94.59 valid_loss nan valid_acc nan val_fscorenan test_loss 1.5094 test_acc 56.5 test_fscore 56.25 time 8.14\n",
            "epoch 38 train_loss 0.1734 train_acc 94.84 train_fscore94.83 valid_loss nan valid_acc nan val_fscorenan test_loss 1.5356 test_acc 56.07 test_fscore 55.71 time 8.18\n",
            "epoch 39 train_loss 0.1757 train_acc 94.39 train_fscore94.37 valid_loss nan valid_acc nan val_fscorenan test_loss 1.5695 test_acc 56.25 test_fscore 55.86 time 7.8\n",
            "epoch 40 train_loss 0.1743 train_acc 94.8 train_fscore94.79 valid_loss nan valid_acc nan val_fscorenan test_loss 1.5976 test_acc 56.56 test_fscore 56.17 time 7.54\n",
            "epoch 41 train_loss 0.1888 train_acc 94.6 train_fscore94.58 valid_loss nan valid_acc nan val_fscorenan test_loss 1.5967 test_acc 56.32 test_fscore 56.03 time 8.59\n",
            "epoch 42 train_loss 0.1652 train_acc 95.32 train_fscore95.31 valid_loss nan valid_acc nan val_fscorenan test_loss 1.564 test_acc 56.62 test_fscore 56.41 time 7.86\n",
            "epoch 43 train_loss 0.1627 train_acc 95.25 train_fscore95.24 valid_loss nan valid_acc nan val_fscorenan test_loss 1.5448 test_acc 55.88 test_fscore 55.66 time 8.52\n",
            "epoch 44 train_loss 0.1672 train_acc 94.92 train_fscore94.91 valid_loss nan valid_acc nan val_fscorenan test_loss 1.5539 test_acc 56.01 test_fscore 55.78 time 7.8\n",
            "epoch 45 train_loss 0.1722 train_acc 94.96 train_fscore94.94 valid_loss nan valid_acc nan val_fscorenan test_loss 1.5777 test_acc 56.44 test_fscore 56.24 time 7.71\n",
            "epoch 46 train_loss 0.1714 train_acc 95.04 train_fscore95.03 valid_loss nan valid_acc nan val_fscorenan test_loss 1.6052 test_acc 56.07 test_fscore 55.88 time 7.59\n",
            "epoch 47 train_loss 0.1628 train_acc 95.37 train_fscore95.36 valid_loss nan valid_acc nan val_fscorenan test_loss 1.6066 test_acc 56.07 test_fscore 55.83 time 8.05\n",
            "epoch 48 train_loss 0.1502 train_acc 95.44 train_fscore95.43 valid_loss nan valid_acc nan val_fscorenan test_loss 1.6028 test_acc 55.82 test_fscore 55.6 time 8.15\n",
            "epoch 49 train_loss 0.1601 train_acc 95.23 train_fscore95.22 valid_loss nan valid_acc nan val_fscorenan test_loss 1.5949 test_acc 55.82 test_fscore 55.63 time 7.76\n",
            "epoch 50 train_loss 0.1556 train_acc 95.54 train_fscore95.53 valid_loss nan valid_acc nan val_fscorenan test_loss 1.5896 test_acc 56.25 test_fscore 56.12 time 8.16\n",
            "epoch 51 train_loss 0.1557 train_acc 95.34 train_fscore95.33 valid_loss nan valid_acc nan val_fscorenan test_loss 1.608 test_acc 56.13 test_fscore 56.02 time 8.47\n",
            "epoch 52 train_loss 0.1502 train_acc 95.49 train_fscore95.48 valid_loss nan valid_acc nan val_fscorenan test_loss 1.6078 test_acc 56.69 test_fscore 56.54 time 8.4\n",
            "epoch 53 train_loss 0.1442 train_acc 95.9 train_fscore95.9 valid_loss nan valid_acc nan val_fscorenan test_loss 1.6057 test_acc 56.56 test_fscore 56.4 time 7.84\n",
            "epoch 54 train_loss 0.1529 train_acc 95.46 train_fscore95.45 valid_loss nan valid_acc nan val_fscorenan test_loss 1.6158 test_acc 55.95 test_fscore 55.81 time 8.25\n",
            "epoch 55 train_loss 0.1414 train_acc 95.61 train_fscore95.6 valid_loss nan valid_acc nan val_fscorenan test_loss 1.6314 test_acc 56.13 test_fscore 55.98 time 7.8\n",
            "epoch 56 train_loss 0.14 train_acc 95.78 train_fscore95.78 valid_loss nan valid_acc nan val_fscorenan test_loss 1.6387 test_acc 56.13 test_fscore 56.08 time 8.35\n",
            "epoch 57 train_loss 0.1453 train_acc 96.01 train_fscore96.0 valid_loss nan valid_acc nan val_fscorenan test_loss 1.6196 test_acc 56.44 test_fscore 56.41 time 8.0\n",
            "epoch 58 train_loss 0.1426 train_acc 95.59 train_fscore95.58 valid_loss nan valid_acc nan val_fscorenan test_loss 1.6131 test_acc 56.62 test_fscore 56.57 time 8.22\n",
            "epoch 59 train_loss 0.1468 train_acc 95.59 train_fscore95.58 valid_loss nan valid_acc nan val_fscorenan test_loss 1.6317 test_acc 56.5 test_fscore 56.43 time 8.14\n",
            "epoch 60 train_loss 0.135 train_acc 96.06 train_fscore96.05 valid_loss nan valid_acc nan val_fscorenan test_loss 1.6508 test_acc 56.13 test_fscore 56.07 time 8.02\n",
            "Test performance..\n",
            "Loss 0.9228 accuracy 63.96\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.4500    0.2500    0.3214     144.0\n",
            "           1     0.8826    0.8286    0.8547     245.0\n",
            "           2     0.5776    0.5911    0.5843     384.0\n",
            "           3     0.6340    0.5706    0.6006     170.0\n",
            "           4     0.6534    0.8763    0.7486     299.0\n",
            "           5     0.5820    0.5591    0.5703     381.0\n",
            "\n",
            "    accuracy                         0.6396    1623.0\n",
            "   macro avg     0.6299    0.6126    0.6133    1623.0\n",
            "weighted avg     0.6332    0.6396    0.6305    1623.0\n",
            "\n",
            "[[ 36.   1.  13.   0.  94.   0.]\n",
            " [  8. 203.   5.   0.   1.  28.]\n",
            " [ 12.  16. 227.  25.  37.  67.]\n",
            " [  0.   0.  17.  97.   0.  56.]\n",
            " [ 24.   0.  11.   0. 262.   2.]\n",
            " [  0.  10. 120.  31.   7. 213.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11mzB5W-pbAh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
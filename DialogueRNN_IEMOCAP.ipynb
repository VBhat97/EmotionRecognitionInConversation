{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DialogueRNN_IEMOCAP.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anitayadav3/EmotionRecognitionInConversation/blob/master/DialogueRNN_IEMOCAP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGkdRLGlKpxy",
        "outputId": "64d9e471-968c-4adb-8a28-6509c1026855",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "!pip install torch_sparse"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch_sparse\n",
            "  Downloading https://files.pythonhosted.org/packages/ce/c0/f5ccc280629765cf1e97b601426cad6170d00603cf9836ba52f85d44ac27/torch_sparse-0.6.7.tar.gz\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch_sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->torch_sparse) (1.18.5)\n",
            "Building wheels for collected packages: torch-sparse\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.6.7-cp36-cp36m-linux_x86_64.whl size=22081958 sha256=8105c619f018190eb6d16d67beb23788e97b54f1501200c719f55da3c63c7efa\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/54/57/495938ad744a865b8933e76fa71853495f2ac476475d49a9a2\n",
            "Successfully built torch-sparse\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPmAS7KfPymU",
        "outputId": "241fe284-7101-4917-9016-48a8ee31d5fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "!pip install torch_scatter"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch_scatter\n",
            "  Using cached https://files.pythonhosted.org/packages/01/45/cd93ed3227248773ba8bc4b3beaa04e8bddb127a793a41bad875369951b3/torch_scatter-2.0.5.tar.gz\n",
            "Building wheels for collected packages: torch-scatter\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.0.5-cp36-cp36m-linux_x86_64.whl size=11359446 sha256=2e5b27c3a951eb3f5c82e93a307ab2ccd5a0317c437d2bc2a5ea87b5d66129a8\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/59/d3/9866e4fd8e1fe9260740acfe22322c428bc0dc064d3ebc456c\n",
            "Successfully built torch-scatter\n",
            "Installing collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITpsd3n93n1B",
        "outputId": "22c54f84-8442-40f4-f951-e65cfa8ab669",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QmfMDch3yss",
        "outputId": "26eca9e6-d080-4e3a-f3b7-ef5cf05d7a3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/drive/My Drive/DialogueRNN"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/DialogueRNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8lbv2Iss1M_"
      },
      "source": [
        "#!python train_IEMOCAP.py --dropout 0.4 --lr 0.0003 --batch-size 32 --class-weight --l2 0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11mzB5W-pbAh"
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(1234)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torch.optim as optim\n",
        "import argparse\n",
        "import time\n",
        "import pickle\n",
        "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score,\\\n",
        "                        classification_report, precision_recall_fscore_support\n",
        "from model import BiModel, Model, MaskedNLLLoss\n",
        "from dataloader import IEMOCAPDataset"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0m16s1gYrwD"
      },
      "source": [
        "def get_train_valid_sampler(trainset, valid=0.1):\n",
        "    size = len(trainset)\n",
        "    idx = list(range(size))\n",
        "    split = int(valid*size)\n",
        "    return SubsetRandomSampler(idx[split:]), SubsetRandomSampler(idx[:split])\n",
        "\n",
        "def get_IEMOCAP_loaders(path, batch_size=32, valid=0.1, num_workers=0, pin_memory=False):\n",
        "    trainset = IEMOCAPDataset(path=path)\n",
        "    train_sampler, valid_sampler = get_train_valid_sampler(trainset, valid)\n",
        "    train_loader = DataLoader(trainset,\n",
        "                              batch_size=batch_size,\n",
        "                              sampler=train_sampler,\n",
        "                              collate_fn=trainset.collate_fn,\n",
        "                              num_workers=num_workers,\n",
        "                              pin_memory=pin_memory)\n",
        "    valid_loader = DataLoader(trainset,\n",
        "                              batch_size=batch_size,\n",
        "                              sampler=valid_sampler,\n",
        "                              collate_fn=trainset.collate_fn,\n",
        "                              num_workers=num_workers,\n",
        "                              pin_memory=pin_memory)\n",
        "\n",
        "    testset = IEMOCAPDataset(path=path, train=False)\n",
        "    test_loader = DataLoader(testset,\n",
        "                             batch_size=batch_size,\n",
        "                             collate_fn=testset.collate_fn,\n",
        "                             num_workers=num_workers,\n",
        "                             pin_memory=pin_memory)\n",
        "\n",
        "    return train_loader, valid_loader, test_loader\n",
        "\n",
        "def train_or_eval_model(model, loss_function, dataloader, epoch, optimizer=None, train=False):\n",
        "    losses = []\n",
        "    preds = []\n",
        "    labels = []\n",
        "    masks = []\n",
        "    alphas, alphas_f, alphas_b, vids = [], [], [], []\n",
        "    assert not train or optimizer!=None\n",
        "    if train:\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "    for data in dataloader:\n",
        "        if train:\n",
        "            optimizer.zero_grad()\n",
        "        # import ipdb;ipdb.set_trace()\n",
        "        textf, visuf, acouf, qmask, umask, label =\\\n",
        "                [d.cuda() for d in data[:-1]] if cuda else data[:-1]\n",
        "        #log_prob = model(torch.cat((textf,acouf,visuf),dim=-1), qmask,umask,att2=True) # seq_len, batch, n_classes\n",
        "        log_prob, alpha, alpha_f, alpha_b = model(textf, qmask,umask,att2=True) # seq_len, batch, n_classes\n",
        "        lp_ = log_prob.transpose(0,1).contiguous().view(-1,log_prob.size()[2]) # batch*seq_len, n_classes\n",
        "        labels_ = label.view(-1) # batch*seq_len\n",
        "        loss = loss_function(lp_, labels_, umask)\n",
        "\n",
        "        pred_ = torch.argmax(lp_,1) # batch*seq_len\n",
        "        preds.append(pred_.data.cpu().numpy())\n",
        "        labels.append(labels_.data.cpu().numpy())\n",
        "        masks.append(umask.view(-1).cpu().numpy())\n",
        "\n",
        "        losses.append(loss.item()*masks[-1].sum())\n",
        "        if train:\n",
        "            loss.backward()\n",
        "            if args.tensorboard:\n",
        "                for param in model.named_parameters():\n",
        "                    writer.add_histogram(param[0], param[1].grad, epoch)\n",
        "            optimizer.step()\n",
        "        else:\n",
        "            alphas += alpha\n",
        "            alphas_f += alpha_f\n",
        "            alphas_b += alpha_b\n",
        "            vids += data[-1]\n",
        "\n",
        "    if preds!=[]:\n",
        "        preds  = np.concatenate(preds)\n",
        "        labels = np.concatenate(labels)\n",
        "        masks  = np.concatenate(masks)\n",
        "    else:\n",
        "        return float('nan'), float('nan'), [], [], [], float('nan'),[]\n",
        "\n",
        "    avg_loss = round(np.sum(losses)/np.sum(masks),4)\n",
        "    avg_accuracy = round(accuracy_score(labels,preds,sample_weight=masks)*100,2)\n",
        "    avg_fscore = round(f1_score(labels,preds,sample_weight=masks,average='weighted')*100,2)\n",
        "    return avg_loss, avg_accuracy, labels, preds, masks,avg_fscore, [alphas, alphas_f, alphas_b, vids]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3J9Gu6npY13S"
      },
      "source": [
        "batch_size = 32\n",
        "n_classes  = 6\n",
        "cuda = torch.cuda.is_available()\n",
        "n_epochs   = 60"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdIdIEv8Y51V"
      },
      "source": [
        "D_m = 100\n",
        "D_g = 500\n",
        "D_p = 500\n",
        "D_e = 300\n",
        "D_h = 300\n",
        "D_a = 100 # concat attention"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctiBkNI1Y7Q-"
      },
      "source": [
        "model = BiModel(D_m, D_g, D_p, D_e, D_h,\n",
        "                n_classes=n_classes,\n",
        "                listener_state=False,\n",
        "                context_attention='general',\n",
        "                dropout_rec=0.1,\n",
        "                dropout=0.4)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvZQfmQVZAbt",
        "outputId": "b44efb40-d90d-4bf2-93a2-70d35ea21bd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        }
      },
      "source": [
        "model.cuda()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BiModel(\n",
              "  (dropout): Dropout(p=0.4, inplace=False)\n",
              "  (dropout_rec): Dropout(p=0.55, inplace=False)\n",
              "  (dialog_rnn_f): DialogueRNN(\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (dialogue_cell): DialogueRNNCell(\n",
              "      (g_cell): GRUCell(600, 500)\n",
              "      (p_cell): GRUCell(600, 500)\n",
              "      (e_cell): GRUCell(500, 300)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "      (attention): MatchingAttention(\n",
              "        (transform): Linear(in_features=100, out_features=500, bias=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dialog_rnn_r): DialogueRNN(\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (dialogue_cell): DialogueRNNCell(\n",
              "      (g_cell): GRUCell(600, 500)\n",
              "      (p_cell): GRUCell(600, 500)\n",
              "      (e_cell): GRUCell(500, 300)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "      (attention): MatchingAttention(\n",
              "        (transform): Linear(in_features=100, out_features=500, bias=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (linear): Linear(in_features=600, out_features=600, bias=True)\n",
              "  (smax_fc): Linear(in_features=600, out_features=6, bias=True)\n",
              "  (matchatt): MatchingAttention(\n",
              "    (transform): Linear(in_features=600, out_features=600, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vziE5FcZIj3"
      },
      "source": [
        "loss_weights = torch.FloatTensor([\n",
        "                                    1/0.086747,\n",
        "                                    1/0.144406,\n",
        "                                    1/0.227883,\n",
        "                                    1/0.160585,\n",
        "                                    1/0.127711,\n",
        "                                    1/0.252668,\n",
        "                                      ])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlHNr1jgZKAa"
      },
      "source": [
        "loss_function = MaskedNLLLoss(loss_weights.cuda())"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxmX1pGLZwBl"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(),\n",
        "                           lr=0.0003,\n",
        "                           weight_decay=0.0)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qg9TRXLWZ2go"
      },
      "source": [
        "train_loader, valid_loader, test_loader =\\\n",
        "            get_IEMOCAP_loaders('./IEMOCAP_features/IEMOCAP_features_raw.pkl',\n",
        "                                valid=0.0,\n",
        "                                batch_size=batch_size,\n",
        "                                num_workers=2)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuQZVMhPZ4eS"
      },
      "source": [
        "best_loss, best_label, best_pred, best_mask = None, None, None, None"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1Pb9f7piRuZ"
      },
      "source": [
        "test_cell = nn.GRUCell(100,100,True)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2yV_tAyZ6CJ"
      },
      "source": [
        "losses = []\n",
        "preds = []\n",
        "labels = []\n",
        "masks = []\n",
        "alphas, alphas_f, alphas_b, vids = [], [], [], []\n",
        "\n",
        "dataloader=train_loader\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIVUmaZkgXae"
      },
      "source": [
        "for data in dataloader:\n",
        "  optimizer.zero_grad()\n",
        "  textf, visuf, acouf, qmask, umask, label =\\\n",
        "                [d.cuda() for d in data[:-1]] if cuda else data[:-1]\n",
        "  log_prob, alpha, alpha_f, alpha_b = model(textf, qmask,umask,att2=True)\n",
        "  lp_ = log_prob.transpose(0,1).contiguous().view(-1,log_prob.size()[2])\n",
        "  labels_ = label.view(-1)\n",
        "  loss = loss_function(lp_, labels_, umask)\n",
        "  pred_ = torch.argmax(lp_,1)\n",
        "  preds.append(pred_.data.cpu().numpy())\n",
        "  labels.append(labels_.data.cpu().numpy())\n",
        "  masks.append(umask.view(-1).cpu().numpy())\n",
        "  losses.append(loss.item()*masks[-1].sum())\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYUYK1ifiaMf"
      },
      "source": [
        "if preds!=[]:\n",
        "  preds  = np.concatenate(preds)\n",
        "  labels = np.concatenate(labels)\n",
        "  masks  = np.concatenate(masks)\n",
        "else:\n",
        "  print(float('nan'), float('nan'), [], [], [], float('nan'),[])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHWl6Mo6ic4Q"
      },
      "source": [
        "avg_loss = round(np.sum(losses)/np.sum(masks),4)\n",
        "avg_accuracy = round(accuracy_score(labels,preds,sample_weight=masks)*100,2)\n",
        "avg_fscore = round(f1_score(labels,preds,sample_weight=masks,average='weighted')*100,2)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxCTSYLJigC1",
        "outputId": "49cd740d-4dfb-43f4-e5a4-185d1f5cdbb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "print(avg_loss)\n",
        "print(avg_accuracy)\n",
        "print(labels)\n",
        "print(preds)\n",
        "print(masks)\n",
        "print(avg_fscore)\n",
        "print([alphas, alphas_f, alphas_b, vids])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.6767\n",
            "33.86\n",
            "[2 4 5 ... 0 0 0]\n",
            "[3 4 4 ... 4 4 4]\n",
            "[1. 1. 1. ... 0. 0. 0.]\n",
            "31.28\n",
            "[[], [], [], []]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
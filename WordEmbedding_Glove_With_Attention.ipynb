{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WordEmbedding_Glove.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anitayadav3/EmotionRecognitionInConversation/blob/master/WordEmbedding_Glove_With_Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9Qq6o94hrVP",
        "outputId": "d862d6eb-7a48-4859-d1db-6504cf4b4976",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQSquAK3jKrj"
      },
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras\n",
        "import itertools\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, LSTM, Embedding, Bidirectional, Input\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical  \n",
        "\n",
        "from keras.layers import Layer\n",
        "import keras.backend as K"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Td2pGheih0Gc",
        "outputId": "f94b4704-0004-46ab-a240-661dce7389ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "glove_6B_100d_file_path_name = \"/content/gdrive/My Drive/iemocap/glove.6B.100d.txt\"\n",
        "\n",
        "embeddings_index = dict()\n",
        "\n",
        "f = open(glove_6B_100d_file_path_name)\n",
        "\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "    \n",
        "f.close()\n",
        "print('Loaded %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd5nzx9Kit7K"
      },
      "source": [
        "all_glove_words = list(embeddings_index.keys())\n",
        "vocabulary_size = len(all_glove_words)\n",
        "tokenizer = Tokenizer() #num_words= vocabulary_size\n",
        "tokenizer.fit_on_texts(all_glove_words)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjyGBwROkdDw",
        "outputId": "536d867e-7140-49c1-82b1-d32c0fe6e47b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(len(all_glove_words))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fO2T4gWTi12N"
      },
      "source": [
        "embedding_matrix = np.zeros((vocabulary_size, 100)) \n",
        "for word, index in tokenizer.word_index.items():\n",
        "    if index > vocabulary_size - 1:\n",
        "        break\n",
        "    else:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[index] = embedding_vector"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TklQP8ii5Br"
      },
      "source": [
        "with open('/content/gdrive/My Drive/iemocap/train/sentences.pkl', 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "with open('/content/gdrive/My Drive/iemocap/train/labels.pkl', 'rb') as f:\n",
        "    labels = pickle.load(f)\n",
        "with open('/content/gdrive/My Drive/iemocap/test/sentences.pkl', 'rb') as f:\n",
        "    test_data = pickle.load(f)\n",
        "with open('/content/gdrive/My Drive/iemocap/test/labels.pkl', 'rb') as f:\n",
        "    test_labels = pickle.load(f)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TII6K0-3jWiv"
      },
      "source": [
        "def preprocessing(data,labels):\n",
        "  processed_data=[]\n",
        "  processed_label=[]\n",
        "  for i in range(0,len(data)):\n",
        "    for j in range(0,len(data[i])):\n",
        "      intermediate_data=[]\n",
        "      intermediate_label=[]\n",
        "      for k in range(0,len(data[i][j])):\n",
        "        text=data[i][j][k]\n",
        "        if text != '<eos>'and text!='<pad>':\n",
        "          intermediate_data.append(text)\n",
        "      processed_data.append(intermediate_data)\n",
        "  for i in labels:\n",
        "    for j in i:\n",
        "      processed_label.append(j)\n",
        "  return processed_data,processed_label"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Vv6Px6ujYqP"
      },
      "source": [
        "processed_data,processed_label = preprocessing(data,labels)\n",
        "test_processed_data,test_processed_label = preprocessing(test_data,test_labels)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIYKt_k5jcRK"
      },
      "source": [
        "def Tokenize(processed_data,processed_label):\n",
        "  X = tokenizer.texts_to_sequences(processed_data)\n",
        "  X = pad_sequences(X)\n",
        "  Y = to_categorical(processed_label, num_classes=6)\n",
        "  return X,Y"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2uLqK_Yjep7"
      },
      "source": [
        "X,Y = Tokenize(processed_data, processed_label)\n",
        "test_X , test_Y = Tokenize(test_processed_data,test_processed_label)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR3zo9nN1r8p"
      },
      "source": [
        "class attention(Layer):\n",
        "    def __init__(self,**kwargs):\n",
        "        super(attention,self).__init__(**kwargs)\n",
        "\n",
        "    def build(self,input_shape):\n",
        "        self.W=self.add_weight(name=\"att_weight\",shape=(input_shape[-1],1),initializer=\"normal\")\n",
        "        self.b=self.add_weight(name=\"att_bias\",shape=(input_shape[1],1),initializer=\"zeros\")        \n",
        "        super(attention, self).build(input_shape)\n",
        "\n",
        "    def call(self,x):\n",
        "        et=K.squeeze(K.tanh(K.dot(x,self.W)+self.b),axis=-1)\n",
        "        at=K.softmax(et)\n",
        "        at=K.expand_dims(at,axis=-1)\n",
        "        output=x*at\n",
        "        return K.sum(output,axis=1)\n",
        "\n",
        "    def compute_output_shape(self,input_shape):\n",
        "        return (input_shape[0],input_shape[-1])\n",
        "\n",
        "    def get_config(self):\n",
        "        return super(attention,self).get_config()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZZx7Iv-1-kL",
        "outputId": "5c69a0aa-53f4-44c4-8090-a20cd25ffaa5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "inputs=Input((X.shape[1],))\n",
        "x=Embedding(input_dim=len(all_glove_words),output_dim=32,input_length=X.shape[1],\\\n",
        "            embeddings_regularizer=keras.regularizers.l2(.001))(inputs)\n",
        "att_in=LSTM(200,return_sequences=True,dropout=0.3,recurrent_dropout=0.2)(x)\n",
        "att_out=attention()(att_in)\n",
        "outputs=Dense(6,activation='softmax')(att_out)\n",
        "model=Model(inputs,outputs)\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 29)]              0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 29, 32)            12800000  \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 29, 200)           186400    \n",
            "_________________________________________________________________\n",
            "attention (attention)        (None, 200)               229       \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 6)                 1206      \n",
            "=================================================================\n",
            "Total params: 12,987,835\n",
            "Trainable params: 12,987,835\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOsMTvWvkS0i"
      },
      "source": [
        "# lstm_out = 200\n",
        "# embed_dim=100\n",
        "# model = Sequential()\n",
        "# model.add(Embedding(len(all_glove_words), embed_dim,input_length = X.shape[1],weights=[embedding_matrix],trainable=False))\n",
        "# model.add(Bidirectional(LSTM(200)))\n",
        "# model.add(Dense(6,activation='softmax'))\n",
        "# model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "# print(model.summary())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwvKkMd8k00W",
        "outputId": "f51c7806-81cc-4cab-beb4-fea8c9205712",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
        "history=model.fit(X, Y, epochs = 100,  verbose = 1)\n",
        "score,acc=model.evaluate(test_X,test_Y,verbose=2)\n",
        "print(\"Accuracy : \"+ str(acc))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "147/147 [==============================] - 25s 167ms/step - loss: 2.7646 - accuracy: 0.2539\n",
            "Epoch 2/100\n",
            "147/147 [==============================] - 24s 166ms/step - loss: 1.7120 - accuracy: 0.2809\n",
            "Epoch 3/100\n",
            "147/147 [==============================] - 24s 166ms/step - loss: 1.6668 - accuracy: 0.3120\n",
            "Epoch 4/100\n",
            "147/147 [==============================] - 24s 166ms/step - loss: 1.5914 - accuracy: 0.3452\n",
            "Epoch 5/100\n",
            "147/147 [==============================] - 24s 167ms/step - loss: 1.5234 - accuracy: 0.3856\n",
            "Epoch 6/100\n",
            "147/147 [==============================] - 24s 166ms/step - loss: 1.4505 - accuracy: 0.4339\n",
            "Epoch 7/100\n",
            "147/147 [==============================] - 25s 167ms/step - loss: 1.3791 - accuracy: 0.4690\n",
            "Epoch 8/100\n",
            "147/147 [==============================] - 24s 165ms/step - loss: 1.3334 - accuracy: 0.4912\n",
            "Epoch 9/100\n",
            "147/147 [==============================] - 24s 165ms/step - loss: 1.2772 - accuracy: 0.5210\n",
            "Epoch 10/100\n",
            "147/147 [==============================] - 25s 167ms/step - loss: 1.2343 - accuracy: 0.5463\n",
            "Epoch 11/100\n",
            "147/147 [==============================] - 25s 167ms/step - loss: 1.2008 - accuracy: 0.5582\n",
            "Epoch 12/100\n",
            "147/147 [==============================] - 24s 165ms/step - loss: 1.1601 - accuracy: 0.5761\n",
            "Epoch 13/100\n",
            "147/147 [==============================] - 24s 165ms/step - loss: 1.1309 - accuracy: 0.5965\n",
            "Epoch 14/100\n",
            "147/147 [==============================] - 24s 165ms/step - loss: 1.1039 - accuracy: 0.6191\n",
            "Epoch 15/100\n",
            "147/147 [==============================] - 24s 167ms/step - loss: 1.0866 - accuracy: 0.6252\n",
            "Epoch 16/100\n",
            "147/147 [==============================] - 24s 165ms/step - loss: 1.0636 - accuracy: 0.6355\n",
            "Epoch 17/100\n",
            "147/147 [==============================] - 24s 165ms/step - loss: 1.0409 - accuracy: 0.6452\n",
            "Epoch 18/100\n",
            "147/147 [==============================] - 24s 166ms/step - loss: 1.0189 - accuracy: 0.6461\n",
            "Epoch 19/100\n",
            "147/147 [==============================] - 24s 165ms/step - loss: 1.0110 - accuracy: 0.6595\n",
            "Epoch 20/100\n",
            "147/147 [==============================] - 24s 167ms/step - loss: 0.9953 - accuracy: 0.6672\n",
            "Epoch 21/100\n",
            "147/147 [==============================] - 25s 167ms/step - loss: 0.9810 - accuracy: 0.6710\n",
            "Epoch 22/100\n",
            "147/147 [==============================] - 24s 166ms/step - loss: 0.9601 - accuracy: 0.6746\n",
            "Epoch 23/100\n",
            "147/147 [==============================] - 24s 165ms/step - loss: 0.9570 - accuracy: 0.6721\n",
            "Epoch 24/100\n",
            "147/147 [==============================] - 24s 167ms/step - loss: 0.9441 - accuracy: 0.6895\n",
            "Epoch 25/100\n",
            "147/147 [==============================] - 24s 166ms/step - loss: 0.9269 - accuracy: 0.6910\n",
            "Epoch 26/100\n",
            "147/147 [==============================] - 25s 167ms/step - loss: 0.9141 - accuracy: 0.6987\n",
            "Epoch 27/100\n",
            "147/147 [==============================] - 24s 165ms/step - loss: 0.9085 - accuracy: 0.6993\n",
            "Epoch 28/100\n",
            "147/147 [==============================] - 24s 165ms/step - loss: 0.8835 - accuracy: 0.7114\n",
            "Epoch 29/100\n",
            "147/147 [==============================] - 24s 166ms/step - loss: 0.8852 - accuracy: 0.7099\n",
            "Epoch 30/100\n",
            "147/147 [==============================] - 24s 165ms/step - loss: 0.8764 - accuracy: 0.7131\n",
            "Epoch 31/100\n",
            "147/147 [==============================] - 24s 164ms/step - loss: 0.8642 - accuracy: 0.7182\n",
            "Epoch 32/100\n",
            "147/147 [==============================] - 24s 165ms/step - loss: 0.8610 - accuracy: 0.7185\n",
            "Epoch 33/100\n",
            "147/147 [==============================] - 24s 166ms/step - loss: 0.8488 - accuracy: 0.7236\n",
            "Epoch 34/100\n",
            "147/147 [==============================] - 24s 166ms/step - loss: 0.8475 - accuracy: 0.7208\n",
            "Epoch 35/100\n",
            "147/147 [==============================] - 24s 165ms/step - loss: 0.8359 - accuracy: 0.7248\n",
            "Epoch 36/100\n",
            "147/147 [==============================] - 24s 166ms/step - loss: 0.8292 - accuracy: 0.7340\n",
            "Epoch 37/100\n",
            "147/147 [==============================] - 25s 167ms/step - loss: 0.8057 - accuracy: 0.7365\n",
            "Epoch 38/100\n",
            "147/147 [==============================] - 24s 167ms/step - loss: 0.8163 - accuracy: 0.7329\n",
            "Epoch 39/100\n",
            "147/147 [==============================] - 24s 166ms/step - loss: 0.8100 - accuracy: 0.7351\n",
            "Epoch 40/100\n",
            "147/147 [==============================] - 24s 166ms/step - loss: 0.8032 - accuracy: 0.7419\n",
            "Epoch 41/100\n",
            "147/147 [==============================] - 24s 166ms/step - loss: 0.7915 - accuracy: 0.7404\n",
            "Epoch 42/100\n",
            "147/147 [==============================] - 24s 166ms/step - loss: 0.7847 - accuracy: 0.7427\n",
            "Epoch 43/100\n",
            "147/147 [==============================] - 24s 167ms/step - loss: 0.7890 - accuracy: 0.7457\n",
            "Epoch 44/100\n",
            "147/147 [==============================] - 24s 166ms/step - loss: 0.7637 - accuracy: 0.7542\n",
            "Epoch 45/100\n",
            "147/147 [==============================] - 24s 165ms/step - loss: 0.7798 - accuracy: 0.7410\n",
            "Epoch 46/100\n",
            "147/147 [==============================] - 24s 164ms/step - loss: 0.7556 - accuracy: 0.7557\n",
            "Epoch 47/100\n",
            "147/147 [==============================] - 24s 166ms/step - loss: 0.7617 - accuracy: 0.7536\n",
            "Epoch 48/100\n",
            "147/147 [==============================] - 24s 165ms/step - loss: 0.7609 - accuracy: 0.7563\n",
            "Epoch 49/100\n",
            "147/147 [==============================] - 24s 166ms/step - loss: 0.7646 - accuracy: 0.7557\n",
            "Epoch 50/100\n",
            "147/147 [==============================] - 25s 167ms/step - loss: 0.7483 - accuracy: 0.7593\n",
            "Epoch 51/100\n",
            "147/147 [==============================] - 25s 167ms/step - loss: 0.7502 - accuracy: 0.7644\n",
            "Epoch 52/100\n",
            "147/147 [==============================] - 24s 165ms/step - loss: 0.7326 - accuracy: 0.7687\n",
            "Epoch 53/100\n",
            "147/147 [==============================] - 24s 167ms/step - loss: 0.7221 - accuracy: 0.7708\n",
            "Epoch 54/100\n",
            "147/147 [==============================] - 24s 166ms/step - loss: 0.7231 - accuracy: 0.7704\n",
            "Epoch 55/100\n",
            "147/147 [==============================] - 24s 166ms/step - loss: 0.7146 - accuracy: 0.7761\n",
            "Epoch 56/100\n",
            "147/147 [==============================] - 24s 166ms/step - loss: 0.7127 - accuracy: 0.7729\n",
            "Epoch 57/100\n",
            "147/147 [==============================] - 25s 167ms/step - loss: 0.7131 - accuracy: 0.7695\n",
            "Epoch 58/100\n",
            "147/147 [==============================] - 25s 167ms/step - loss: 0.7107 - accuracy: 0.7785\n",
            "Epoch 59/100\n",
            "147/147 [==============================] - 24s 166ms/step - loss: 0.6848 - accuracy: 0.7829\n",
            "Epoch 60/100\n",
            "147/147 [==============================] - 24s 165ms/step - loss: 0.6826 - accuracy: 0.7768\n",
            "Epoch 61/100\n",
            "147/147 [==============================] - 24s 166ms/step - loss: 0.6884 - accuracy: 0.7846\n",
            "Epoch 62/100\n",
            "147/147 [==============================] - 24s 165ms/step - loss: 0.6959 - accuracy: 0.7753\n",
            "Epoch 63/100\n",
            "147/147 [==============================] - 24s 166ms/step - loss: 0.6793 - accuracy: 0.7908\n",
            "Epoch 64/100\n",
            "147/147 [==============================] - 25s 168ms/step - loss: 0.6771 - accuracy: 0.7897\n",
            "Epoch 65/100\n",
            "147/147 [==============================] - 24s 165ms/step - loss: 0.6621 - accuracy: 0.7912\n",
            "Epoch 66/100\n",
            "147/147 [==============================] - 25s 168ms/step - loss: 0.6590 - accuracy: 0.7902\n",
            "Epoch 67/100\n",
            "147/147 [==============================] - 24s 166ms/step - loss: 0.6726 - accuracy: 0.7904\n",
            "Epoch 68/100\n",
            "147/147 [==============================] - 24s 166ms/step - loss: 0.6688 - accuracy: 0.7908\n",
            "Epoch 69/100\n",
            "147/147 [==============================] - 25s 167ms/step - loss: 0.6602 - accuracy: 0.7936\n",
            "Epoch 70/100\n",
            "147/147 [==============================] - 25s 167ms/step - loss: 0.6516 - accuracy: 0.7902\n",
            "Epoch 71/100\n",
            "147/147 [==============================] - 24s 166ms/step - loss: 0.6470 - accuracy: 0.7976\n",
            "Epoch 72/100\n",
            "147/147 [==============================] - 24s 166ms/step - loss: 0.6439 - accuracy: 0.8025\n",
            "Epoch 73/100\n",
            "147/147 [==============================] - 25s 167ms/step - loss: 0.6471 - accuracy: 0.7957\n",
            "Epoch 74/100\n",
            "147/147 [==============================] - 25s 167ms/step - loss: 0.6439 - accuracy: 0.8040\n",
            "Epoch 75/100\n",
            "147/147 [==============================] - 24s 166ms/step - loss: 0.6278 - accuracy: 0.8055\n",
            "Epoch 76/100\n",
            "147/147 [==============================] - 24s 167ms/step - loss: 0.6290 - accuracy: 0.8057\n",
            "Epoch 77/100\n",
            "147/147 [==============================] - 25s 168ms/step - loss: 0.6262 - accuracy: 0.8085\n",
            "Epoch 78/100\n",
            "147/147 [==============================] - 24s 166ms/step - loss: 0.6196 - accuracy: 0.8129\n",
            "Epoch 79/100\n",
            "147/147 [==============================] - 25s 167ms/step - loss: 0.6176 - accuracy: 0.8078\n",
            "Epoch 80/100\n",
            "147/147 [==============================] - 25s 167ms/step - loss: 0.6236 - accuracy: 0.8104\n",
            "Epoch 81/100\n",
            "147/147 [==============================] - 24s 165ms/step - loss: 0.6168 - accuracy: 0.8121\n",
            "Epoch 82/100\n",
            "147/147 [==============================] - 24s 165ms/step - loss: 0.6042 - accuracy: 0.8129\n",
            "Epoch 83/100\n",
            "147/147 [==============================] - 24s 166ms/step - loss: 0.6049 - accuracy: 0.8153\n",
            "Epoch 84/100\n",
            "147/147 [==============================] - 24s 165ms/step - loss: 0.6096 - accuracy: 0.8108\n",
            "Epoch 85/100\n",
            "147/147 [==============================] - 24s 166ms/step - loss: 0.6102 - accuracy: 0.8104\n",
            "Epoch 86/100\n",
            "147/147 [==============================] - 24s 166ms/step - loss: 0.5987 - accuracy: 0.8183\n",
            "Epoch 87/100\n",
            "147/147 [==============================] - 24s 165ms/step - loss: 0.6014 - accuracy: 0.8151\n",
            "Epoch 88/100\n",
            "147/147 [==============================] - 24s 165ms/step - loss: 0.5947 - accuracy: 0.8240\n",
            "Epoch 89/100\n",
            "147/147 [==============================] - 24s 167ms/step - loss: 0.5788 - accuracy: 0.8221\n",
            "Epoch 90/100\n",
            "147/147 [==============================] - 24s 165ms/step - loss: 0.5881 - accuracy: 0.8210\n",
            "Epoch 91/100\n",
            "147/147 [==============================] - 24s 166ms/step - loss: 0.5896 - accuracy: 0.8189\n",
            "Epoch 92/100\n",
            "147/147 [==============================] - 25s 167ms/step - loss: 0.5831 - accuracy: 0.8240\n",
            "Epoch 93/100\n",
            "147/147 [==============================] - 25s 167ms/step - loss: 0.5775 - accuracy: 0.8276\n",
            "Epoch 94/100\n",
            "147/147 [==============================] - 25s 167ms/step - loss: 0.5887 - accuracy: 0.8221\n",
            "Epoch 95/100\n",
            "147/147 [==============================] - 25s 168ms/step - loss: 0.5780 - accuracy: 0.8255\n",
            "Epoch 96/100\n",
            "147/147 [==============================] - 25s 167ms/step - loss: 0.5680 - accuracy: 0.8272\n",
            "Epoch 97/100\n",
            "147/147 [==============================] - 24s 166ms/step - loss: 0.5746 - accuracy: 0.8283\n",
            "Epoch 98/100\n",
            "147/147 [==============================] - 24s 166ms/step - loss: 0.5599 - accuracy: 0.8332\n",
            "Epoch 99/100\n",
            "147/147 [==============================] - 24s 167ms/step - loss: 0.5594 - accuracy: 0.8336\n",
            "Epoch 100/100\n",
            "147/147 [==============================] - 24s 165ms/step - loss: 0.5663 - accuracy: 0.8246\n",
            "51/51 - 1s - loss: 2.4046 - accuracy: 0.4677\n",
            "Accuracy : 0.46765249967575073\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwkpJ7_KNuSI",
        "outputId": "ca1da29e-c18e-4556-a0ec-357cff7be120",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import keras\n",
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}